---
title: "lista_3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## ExercÃ­cios Multipla Escolha 

1. D
2. C
3. C
4. C
5. A
6. C
7. C

## Questao 1. 
```{r Questao 1, message=FALSE, warning=FALSE}
library(datasets)
library(caret)
library(varhandle)
library(e1071)

# 1
data <- iris
species <- to.dummy(data$Species, "species")
species <- as.data.frame(species)
unique(species)

Species <- species$species.virginica
Species
data <- data.frame(data[,1:4], Species)

# 2
data["Species"] <- lapply(data["Species"], factor) 
str(data)

# 3
species <- data$Species
species
unique(species)
size = dim(data)

# 4
set.seed(12)

index <- createDataPartition(data$Species, p = 0.9, list = FALSE)
index

treino <-data[index,]
teste <- data[-index,]

# 5
ggplot(treino, aes(x = treino$Petal.Length, y = treino$Petal.Width, color=Species)) + 
  geom_point() + 
  scale_color_discrete(labels = c("N Virginica","Virginica"))+
  ylab('Width') + 
  xlab('Lenght')

# 6 7 8
modelo <- glm(as.formula(" Species ~ ."), data = treino, family = 'binomial')
summary(modelo)

# 9
pred <- as.factor(round(as.numeric(predict(modelo, teste, type="response"))))
factors = as.factor(teste$Species)
pred_data <- data.frame(pred, factors)
confusionMatrix(data = pred, reference = factors, positive = "1")

# 10
flor1 <- data.frame(Sepal.Length=6.4, Sepal.Width=2.8, Petal.Length=4.6, Petal.Width=1.8)
flor2 <- data.frame(Sepal.Length=6.3, Sepal.Width=2.5, Petal.Length=4.1, Petal.Width=1.7)
pred_1 <- predict(modelo, flor1, type = 'response')
pred_2 <- predict(modelo, flor2, type = 'response')
pred_1
pred_2

```
---
## Questao 2.
```{r Questao 2, message=FALSE, warning=FALSE}
library(caret)
library(ROCR)
library(e1071)

# 1 2 
data <- read.csv("credit_dataset.csv", header = TRUE, sep = ',')
str(data)
View(data)

# 3
data$credit.duration.months <- scale(data$credit.duration.months, center = T, scale = T)
data$age <- scale(data$age, center = T, scale = T)
data$credit.amount <- scale(data$credit.duration.months, center = T, scale = T)

asfactor <- function(df , variaveis){
  # Loop para todas as variÃƒÂ¡veis
  for (variavel in variaveis){
  # ConversÃƒÂ£o para fator
  df[[variavel]] <- as.factor(df[[variavel]])
  }
  return(df)
}

# 4

colnames(data)
variaveis <- c('credit.rating','account.balance','previous.credit.payment.status','credit.purpose','savings','employment.duration','installment.rate','marital.status','guarantor','residence.duration','current.assets','other.credits','apartment.type','bank.credits', 'occupation','dependents', 'telephone','foreign.worker')

data_factor <- asfactor(data, variaveis)
str(data_factor)
View(data_factor)

# ----------------------------------------------------------------------
# PreparaÃƒÂ§ÃƒÂ£o dos dados de treinamento e teste

# Vamos usar a funÃƒÂ§ÃƒÂ£o sample, do pacote base do R, para extrair uma porcentagem (%) de dados do conjunto dataset 
# para a fase de treinamento, permitindo que o restante de dados seja usado para teste.

# Para reproduÃƒÂ§ÃƒÂ£o dos resultados
set.seed(90)

# Vamos gerar o vetor de Ãƒ­ndices com posiÃƒÂ§ÃƒÂµes aleatÃƒÂ³rias que capturam 60% dos dados para treinamento
index_training = sample(1:nrow(data_normalizado_factor), size = 0.6*nrow(data_normalizado_factor))

# Dicas:
# 1) a funÃƒÂ§ÃƒÂ£o nrow nos fornece o nÃƒÂºmero de linhas do dataset (row)
# 2) o parÃƒÂ¢metro size nos permite especificar o tamanho da amostra capturada para treino do modelo
# 3) a variÃƒÂ¡vel index_training ÃƒÂ© um vetor com posiÃƒÂ§ÃƒÂµes ou Ãƒ­ndices que nos permitem capturar dados especÃƒ­ficos do dataset para treinamento

# Com o vetor de Ãƒ­ndices de treinamento criado - podemos obter os conjuntos de treino e teste
training_data = data_normalizado_factor[index_training,]
test_data     = data_normalizado_factor[-index_training,]

# Dicas:
# 1) repare na notaÃƒÂ§ÃƒÂ£o do R para acessarmos o dataset por meio de Ãƒ­ndices
# 2) quando usamos a sintaxe [index,] -> quer dizer que queremos as linhas apontadas pelo Ãƒ­ndice de todas as colunas
# 3) quando usamos a sintaxe [-index,] -> o sinal de negativo - quer dizer que queremos as linhas que nÃƒÂ£o sÃƒÂ£o apontadas pelo Ãƒ­ndice de todas as colunas
# 4) essa extraÃƒÂ§ÃƒÂ£o por meio de [] ÃƒÂ© denotada como slicing de dataframes

# VisulizaÃƒÂ§ÃƒÂ£o dos conjuntos de treinamento e teste
View(training_data)
View(test_data)

# Repare tambÃƒÂ©m que os conjuntos de treinamento e teste sÃƒÂ£o dataframes
class(training_data)
class(test_data)

# Veja que o objetivo do modelo de regressÃƒÂ£o logÃƒ­stica ÃƒÂ© fazer classificaÃƒÂ§ÃƒÂµes sobre crÃƒÂ©dito 
# Ressaltando -> a variÃƒÂ¡vel target - de saÃƒ­da ÃƒÂ© a credit.rating vamos separÃƒÂ¡-la no conjunto de teste
test_features <- test_data[,-1]
test_target   <- test_data[,1]

# VerificaÃƒÂ§ÃƒÂ£o das classes das variÃƒÂ¡veis explanatÃƒÂ³rias e a variÃƒÂ¡vel de saÃƒ­da
class(test_features)
class(test_target)

# =======================================================================================================
# ConstruÃƒÂ§ÃƒÂ£o do Modelo Preditivo com RegressÃƒÂ£o LogÃƒ­stica  

# Vamos criar o objeto referente ÃƒÂ  equaÃƒÂ§ÃƒÂ£o de relaÃƒÂ§ÃƒÂ£o de variÃƒÂ¡veis do modelo
equation <- "credit.rating ~ ."
class(equation)
equation <- as.formula(equation)
class(equation)

# Dicas:
# 1) estamos criando uma fÃƒÂ³rmula no R 
# 2) do lado esquerdo do ~ colocamos a variÃƒÂ¡vel target ou resposta
# 3) do lado direito do ~ colocamos as variÃƒÂ¡veis explanatÃƒÂ³rias
# 4) quando usamos o . -> estamos apontando o uso de todas as variÃƒÂ¡veis explanatÃƒÂ³rias

# FunÃƒÂ§ÃƒÂ£o usada para construÃƒÂ§ÃƒÂ£o do modelo preditivo de regressÃƒÂ£o logÃƒ­stica
# Fitting Generalized Linear Models
# ?glm
modelo_ML_logistic_1 <- glm(equation, data = training_data, family = "binomial")
modelo_ML_logistic_1


# SÃƒ­ntese das informaÃƒÂ§ÃƒÂµes do modelo
summary(modelo_ML_logistic_1)

# Dicas:
# 1) observem os resultados do summary com atenÃƒÂ§ÃƒÂ£o para verificar quais sÃƒÂ£o as variÃƒÂ¡veis explanatÃƒÂ³rias mais (estatÃƒ­sticamente) significativas para o modelo de ML 
# 2) perceba agora que esse modelo estÃƒÂ¡ fazendo uma classificaÃƒÂ§ÃƒÂ£o, considerando duas classes de saÃƒ­da (aprovaÃƒÂ§ÃƒÂ£o ou desaprovaÃƒÂ§ÃƒÂ£o) de crÃƒÂ©dito
# 3) dbservem que tambÃƒÂ©m existem estatÃƒ­sticas relacionadas com os resÃƒ­duos do modelo treinado
# 4) observem a estatÃƒ­stica z e seu p-value -> recordando do tÃƒÂ³pico sobre testes de hipÃƒÂ³teses que vimos na aula de revisÃƒÂ£o 
# 5) o parÃƒÂ¢metro binomial para a famÃƒ­lia da regressÃƒÂ£o logÃƒ­stica ÃƒÂ© usado pois a classe de saÃƒ­da sÃƒÂ³ pode assumir dois valores (1 ou 0)
# 6) a funÃƒÂ§ÃƒÂ£o glm pode ser usada para criar diferentes modelos - e o parÃƒÂ¢metro family ÃƒÂ© o que permite diferenciar os modelos


# -------------------------------------------------------------------------------------------------------------------------
# Fazendo as prediÃƒÂ§ÃƒÂµes a partir do modelo treinado

# View(test_data)
previsao_teste <- predict(modelo_ML_logistic_1, test_data, type = 'response')
previsao_teste
# View(previsao_teste)

# Repare que a funÃƒÂ§ÃƒÂ£o predict nos fornece a previsÃƒÂ£o de cada classe expressa por probabilidades
# Nesse caso, podemos usar a funÃƒÂ§ÃƒÂ£o round para fazer o arredondamento para as classes desejadas (0 e 1) nesse caso binomial
previsao_teste <- round(previsao_teste)
# View(previsao_teste)
# View(test_target)

previsao_teste_data <- data.frame(previsao_teste, test_target)
colnames(previsao_teste_data) <- c('PrevisÃƒÂ£o','Target')
# View(previsao_teste_data)

# -----------------------------------------------------------------------------------------------------------------------
# ImplementaÃƒÂ§ÃƒÂ£o da Matriz de ConfusÃƒÂ£o

# ConstruÃƒÂ§ÃƒÂ£o da matriz de confusÃƒÂ£o a partir dos dados de teste e as previsÃƒÂµes realizadas pelo modelo de ML
cm_modelo_1 <- confusionMatrix(table(data = previsao_teste, reference = test_target), positive = "1")
cm_modelo_1

# Dicas:
# 1) Observe na referÃƒÂªncia de ajuste - as definiÃƒÂ§ÃƒÂµes e interpretaÃƒÂ§ÃƒÂµes da sÃƒ­ntese estatÃƒ­stica fornecida junto com a matriz de confusÃƒÂ£o
# 2) Compare com os slides que vimos na primeira aula (conceitos de ML) no momento em que abordamos as mÃƒÂ©tricas de performance dos modelos de ML
# 3) Boa referÃƒÂªncia para compreeender a matriz de confusÃƒÂ£o e o package caret: Kuhn, M. (2008), Ã¢Â€ÂœBuilding predictive models in R using the caret package
# 4) A acurÃƒÂ¡cia calculada ÃƒÂ© uma das principais mÃƒÂ©tricas e serem utilizadas na avaliaÃƒÂ§ÃƒÂ£o de desempenho dos classificadores

# ========================================================================================================================
# SeleÃƒÂ§ÃƒÂ£o de VariÃƒÂ¡veis ExplanatÃƒÂ³rias (Feature Selection) para Modelagem

equation <- "credit.rating ~ ."
equation <- as.formula(equation)

# Uso da funÃƒÂ§ÃƒÂ£o trainControl - trata-se de uma funÃƒÂ§ÃƒÂ£o do pacote caret para que possamos aplicar um procedimento de 
# controle sobre diversos treinamentos. Repare que usamos o mÃƒÂ©todo de repetiÃƒÂ§ÃƒÂ£o de validaÃƒÂ§ÃƒÂ£o cruzada
controle_procedimento      <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
modelo_ML_controle_traning <- train(equation, data = training_data, method = 'glm', trControl = controle_procedimento)

# ApÃƒÂ³s as diversas iteraÃƒÂ§ÃƒÂµes de treinamento do modelo, vamos usar a funÃƒÂ§ÃƒÂ£o varImp, tambÃƒÂ©m do pacote caret, que irÃƒÂ¡ 
# nos permite verifica quais sÃƒÂ£o as variÃƒÂ¡veis explanatÃƒÂ³rias mais importantes 
feature_selection = varImp(modelo_ML_controle_traning, scale = TRUE)
# VisualizaÃƒÂ§ÃƒÂ£o das variÃƒÂ¡veis explanatÃƒÂ³rias mais relevantes
plot(feature_selection)



# ========================================================================================================
# --------------------------------------------------------------------------------------------------------
# Avaliando a performance do modelo logistio com todas as variÃƒÂ¡veis explanatÃƒÂ³rias - Modelo 1

# Modelo de regressÃƒÂ£o logÃƒ­stica 1

# PrevisÃƒÂµes do modelo de regressÃƒÂ£o logÃƒ­stica 1
previsao_teste_modelo_1 <- predict(modelo_ML_logistic_1, test_data, type = 'response')
# previsao_teste_modelo_1 <- round(previsao_teste_modelo_1)

# Dataframe - previsÃƒÂ£o do modelo 1
# dataframe_previsao_modelo_1 <- data.frame(previsao_teste_modelo_1, test_target)
# colnames(dataframe_previsao_modelo_1) <- c('PrevisÃƒÂ£o Nova','Target')
# View(dataframe_previsao_modelo_1)

# Repare na diferenÃƒÂ§a entre a funÃƒÂ§ÃƒÂ£o predict e a funÃƒÂ§ÃƒÂ£o prediction
previsoes_finais_modelo_1 <- prediction(previsao_teste_modelo_1, test_target)

# FunÃƒÂ§ÃƒÂ£o que podemos usar para plot da curva ROC 
plot.roc.curve <- function(predictions, title.text){
  perf <- performance(predictions, "tpr", "fpr")
  plot(perf,col = "black",lty = 1, lwd = 2,
       main = title.text, cex.main = 0.6, cex.lab = 0.8,xaxs = "i", yaxs = "i")
  abline(0,1, col = "red")
  auc <- performance(predictions,"auc")
  auc <- unlist(slot(auc, "y.values"))
  auc <- round(auc,2)
  legend(0.4,0.4,legend = c(paste0("AUC: ",auc)), cex = 0.6, bty = "n", box.col = "white")
}

# Plot - quantidade de grÃƒÂ¡ficos na paleta grÃƒÂ¡fica do R
par(mfrow = c(1, 2))
plot.roc.curve(previsoes_finais_modelo_1, title.text = "Curva ROC (Modelo 1)")


# ========================================================================================================================
# A partir da anÃƒÂ¡lise das variÃƒÂ¡veis explanatÃƒÂ³rias mais importantes para o modelo, vamos fazer a modelagem de um novo classificador

# FormulaÃƒÂ§ÃƒÂ£o da equaÃƒÂ§ÃƒÂ£o com as variÃƒÂ¡veis explanatÃƒÂ³rias selecionadas para o modelo
equation_nova <- "credit.rating ~ account.balance + credit.purpose + previous.credit.payment.status + savings + credit.duration.months"
equation_nova <- as.formula(equation_nova)

# FunÃƒÂ§ÃƒÂ£o usada para construÃƒÂ§ÃƒÂ£o do modelo preditivo de regressÃƒÂ£o logÃƒ­stica
modelo_ML_logistic_2 <- glm(equation_nova, data = training_data, family = "binomial")
modelo_ML_logistic_2

# SÃƒ­ntese das informaÃƒÂ§ÃƒÂµes do modelo
summary(modelo_ML_logistic_2)

# Fazendo previsÃƒÂµes com o novo modelo treinado
# Repare que a funÃƒÂ§ÃƒÂ£o predict nos fornece a previsÃƒÂ£o de cada classe expressa por probabilidades
# Nesse caso, podemos usar a funÃƒÂ§ÃƒÂ£o round para fazer o arredondamento para as classes desejadas (0 e 1) nesse caso binomial
previsao_teste_2 <- predict(modelo_ML_logistic_2, test_data, type = 'response')
previsao_teste_2 <- round(previsao_teste_2)

previsao_teste_2_data <- data.frame(previsao_teste_2, test_target)
colnames(previsao_teste_2_data) <- c('PrevisÃƒÂ£o Nova','Target')
# View(previsao_teste_novo_data)

# -----------------------------------------------------------------------------------------------------------------------
# ImplementaÃƒÂ§ÃƒÂ£o da Matriz de ConfusÃƒÂ£o

# ConstruÃƒÂ§ÃƒÂ£o da matriz de confusÃƒÂ£o a partir dos dados de teste e as previsÃƒÂµes realizadas pelo modelo de ML
cm_modelo_2 <- confusionMatrix(table(data = previsao_teste_2, reference = test_target), positive = "1")
# cm_modelo_2

# ========================================================================================================
# --------------------------------------------------------------------------------------------------------
# Avaliando a performance do modelo logistio com todas as variÃƒÂ¡veis explanatÃƒÂ³rias - Modelo 1

# Modelo de regressÃƒÂ£o logÃƒ­stica 2

# PrevisÃƒÂµes do modelo de regressÃƒÂ£o logÃƒ­stica 1
previsao_teste_modelo_2 <- predict(modelo_ML_logistic_2, test_data, type = 'response')
# previsao_teste_modelo_2 <- round(previsao_teste_modelo_2)

# Dataframe - previsÃƒÂ£o do modelo 2
# dataframe_previsao_modelo_2 <- data.frame(previsao_teste_modelo_2, test_target)
# colnames(dataframe_previsao_modelo_2) <- c('PrevisÃƒÂ£o Nova','Target')
# View(dataframe_previsao_modelo_2)

# Repare na diferenÃƒÂ§a entre a funÃƒÂ§ÃƒÂ£o predict e a funÃƒÂ§ÃƒÂ£o prediction
previsoes_finais_modelo_2 <- prediction(previsao_teste_modelo_2, test_target)

# FunÃƒÂ§ÃƒÂ£o que podemos usar para plot da curva ROC 
plot.roc.curve <- function(predictions, title.text){
  perf <- performance(predictions, "tpr", "fpr")
  plot(perf,col = "black",lty = 1, lwd = 2,
       main = title.text, cex.main = 0.6, cex.lab = 0.8,xaxs = "i", yaxs = "i")
  abline(0,1, col = "red")
  auc <- performance(predictions,"auc")
  auc <- unlist(slot(auc, "y.values"))
  auc <- round(auc,2)
  legend(0.4,0.4,legend = c(paste0("AUC: ",auc)), cex = 0.6, bty = "n", box.col = "white")
}

# Plot - quantidade de grÃƒÂ¡ficos na paleta grÃƒÂ¡fica do R
plot.roc.curve(previsoes_finais_modelo_2, title.text = "Curva ROC (Modelo 2)")




```
